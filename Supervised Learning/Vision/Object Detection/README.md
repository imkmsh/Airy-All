# Object Detection

![그림1](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Ftjymm%2FbtqArUrXnYh%2F5m9s2uQIAQ7E5ExfE1dxv0%2Fimg.jpg)

# YOLOv3

- 2015년에 발표된 You Only Look Once
- 당시에는 Faster-R-CNN이 가장 좋은 성능을 내고 있었음
- 처음으로 One-shot-detection 방법 고안
- 이전까진 Two-shot-detection, 실시간성 부족

# Faster-R-CNN

![architecture](https://www.researchgate.net/profile/Zhipeng-Deng-2/publication/324903264/figure/fig2/AS:640145124499471@1529633899620/The-architecture-of-Faster-R-CNN.png)

Faster-RCNN is composed of 3 neural networks — Feature Network, Region Proposal Network (RPN), Detection Network

## Feature Network
- well known pre-trained image classification network such as VGG
- generate good features from the images
- output of this network maintains the the shape and structure of the original image

![Original image](https://miro.medium.com/max/500/1*sKw243AquatVLWsHZ5Bt6Q.png)

↓

  ![Feature](https://miro.medium.com/max/700/1*YWMVZZrj0IxVV54ig92xtg.png)
 
## RPN
- a simple network with a 3 convolutional layers
- one common layer which feeds into a two layers — one for classification and the other for bounding box regression
- generate a number of bounding boxes called Region of Interests (ROIs) that has high probability of containing any object
- output from this network is a number of bounding boxes identified by the pixel co-ordinates of two diagonal corners, and a value(1, 0, or -1, indicating whether an object is in the bounding box or not or the box can be ignored respectively)

### Training

- a number of bounding boxes are generated by a mechanism called anchor boxes
- every ‘pixel’ of the feature image is considered an anchor
- Each anchor corresponds to a larger set of squares of pixel in the original image

![그림](https://miro.medium.com/max/700/1*XEHcNRvRybLzo66F6cn-jg.png)

- anchors are positioned uniformly across both dimensions of the reshaped image
- input that is required from the feature generation layer to generate anchor boxes is the shape of the tensor, not the full feature tensor itself
- a number of rectangular boxes of different shapes and sizes are generated centered on each anchor
- usually 9 boxes are generated per anchor (3 sizes x 3 shapes)

![그림](https://miro.medium.com/max/700/1*CmOhPmqSoDCI_Yk0LWBVbg.png)

- Non-Maximum Suppression (NMS) is used in the fist step of reduction
- NMS removes boxes that overlaps with other boxes that has higher scores ( scores are unnormalized probabilities , e.g. before softmax is applied to normalize)
- about 2000 boxes are extracted during training phase
- they are further reduced through sampling to about 256 before entering the Detection Network  


- to generate labels for RPN classification, IOU of all the bounding boxes against all the ground truth boxes are taken
- the IOUs are used to label the 256 ROIs as foreground and background, and ignored
- these labels are then used to calculate the cross-entropy loss, after first removing the ignored (-1) class boxes


- Bounding box regression: the RPN also tries to tighten the center and the size of the anchor boxes around the target
- for this to happen, targets needs to be generated, and losses needs to be calculated for back propagation
- Target delta vector for the center: the distance vector from the center of the ground truth box to the anchor box is taken and normalized to the size of the anchor box
- The size target is the log of the ratio of size of each dimension of the ground truth over anchor box
- the loss is calculated by using an expression called Smooth L1 Loss


- the regular L1 loss ( e.g. the norm or absolute value) is not differentiable at 0
- smooth L1 Loss overcomes this by using L2 loss near 0
- the extent of L2 loss is tuned by a parameter called sigma

~~~
if abs(d) < 1 / sigma**2
loss = (d * sigma)**2 / 2
else
loss = abs(d) — 1 / (2 * sigma**2)
~~~

- the losses are back propagated the usual way to train RPN
- RPN can be trained by itself, or jointly with the Detection Network

## Detection Network
- input from both the Feature Network and RPN
- generates the final class and bounding box
- composed of 4 Fully Connected or Dense layers
- 2 stacked common layers shared by a classification layer and a bounding box regression layer
- to classify only the inside of the bounding boxes, the features are cropped according to the bounding boxes

### Training
- Detection Network can be considered the removed layers of the classification network that is used for features generation
- starting weights can be pre-loaded from that network before training


- IOUs of all the 2000 or so ROIs generated by the NMS following RPN against each ground truth bounding box is calculated
- the ROIs are labeled as foreground or background depending on the corresponding threshold values
- a fixed number(e.g. 256) ROIs are selected from the foreground and background ones
- If there are not enough foreground and/or background ROIs to fill the fixed number, then some ROIs are duplicated at random


- the features are cropped and scaled to 14 x 14 (max-pooled to 7 x 7 before entering the Detection Network) according to the size of the ROIs (for this, ROI width and heights are scaled to the feature size)

![그림](https://miro.medium.com/max/700/1*nYMbCEJ1OGPy6CiDYIqPPw.png)

- the set of cropped features for each image are passed through the Detection Network as a batch
- final dense layers output for each cropped feature, the score and bounding box for each class (e.g. 256 x C, 256 x 4C in one-hot encoding form, where C is the number of classes)


- to generate label for Detection Network classification, IOUs of all the ROIs and the ground truth boxes are calculated
- depending on IOU thresholds (e.g. foreground above 0.5 , and background between 0.5 and 0.1), labels are generated for a subset of ROIs
- the difference with RPN is that here there are more classes
- classes are encoded in sparse form, instead of one-hot encoding
- following a similar approach to the RPN target generation, bounding box targets are also generated
- these targets are in the compact form as mentioned previously, hence are expanded to the one-hot encoding for calculation of loss.


- the loss calculation is again similar to that of the RPN network
- For classification sparse cross-entropy is used and for bounding boxes, Smooth L1 Loss is used
- the difference with RPN loss is that there are more classes (say 20 including background) to consider instead of just 2 (foreground and background)
